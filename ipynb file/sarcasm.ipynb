{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding,Flatten,Dropout\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28614</th>\n",
       "      <td>https://www.theonion.com/jews-to-celebrate-ros...</td>\n",
       "      <td>jews to celebrate rosh hashasha or something</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28615</th>\n",
       "      <td>https://local.theonion.com/internal-affairs-in...</td>\n",
       "      <td>internal affairs investigator disappointed con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28616</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/andrew-ah...</td>\n",
       "      <td>the most beautiful acceptance speech this week...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28617</th>\n",
       "      <td>https://www.theonion.com/mars-probe-destroyed-...</td>\n",
       "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28618</th>\n",
       "      <td>https://www.theonion.com/dad-clarifies-this-no...</td>\n",
       "      <td>dad clarifies this not a food stop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55328 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            article_link  \\\n",
       "0      https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1      https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2      https://local.theonion.com/mom-starting-to-fea...   \n",
       "3      https://politics.theonion.com/boehner-just-wan...   \n",
       "4      https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "...                                                  ...   \n",
       "28614  https://www.theonion.com/jews-to-celebrate-ros...   \n",
       "28615  https://local.theonion.com/internal-affairs-in...   \n",
       "28616  https://www.huffingtonpost.com/entry/andrew-ah...   \n",
       "28617  https://www.theonion.com/mars-probe-destroyed-...   \n",
       "28618  https://www.theonion.com/dad-clarifies-this-no...   \n",
       "\n",
       "                                                headline  is_sarcastic  \n",
       "0      former versace store clerk sues over secret 'b...             0  \n",
       "1      the 'roseanne' revival catches up to our thorn...             0  \n",
       "2      mom starting to fear son's web series closest ...             1  \n",
       "3      boehner just wants wife to listen, not come up...             1  \n",
       "4      j.k. rowling wishes snape happy birthday in th...             0  \n",
       "...                                                  ...           ...  \n",
       "28614       jews to celebrate rosh hashasha or something             1  \n",
       "28615  internal affairs investigator disappointed con...             1  \n",
       "28616  the most beautiful acceptance speech this week...             0  \n",
       "28617  mars probe destroyed by orbiting spielberg-gat...             1  \n",
       "28618                 dad clarifies this not a food stop             1  \n",
       "\n",
       "[55328 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", 'r',lines=True)\n",
    "dff2 = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\", 'r',lines=True)\n",
    "df =  pd.concat([df2, dff2])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = \" \".join(filter(lambda x:x[0]!='@', text.split()))\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['headline'].values\n",
    "y=df['is_sarcastic'].values\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=3000\n",
    "embedding_dim=32\n",
    "max_len=32\n",
    "trunc_type='post'\n",
    "padding_type='post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x2368a8cf1c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer= Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences=tokenizer.texts_to_sequences(X_train)\n",
    "training_padded=pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_sequences=tokenizer.texts_to_sequences(X_test)\n",
    "testing_padded=pad_sequences(testing_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size,embedding_dim,seq_len):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocabulary_size,embedding_dim,input_length=seq_len))\n",
    "    model.add(LSTM(64,dropout=0.2,recurrent_dropout=0.25))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 32)            96032     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 120,929\n",
      "Trainable params: 120,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "606/606 - 22s - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.3086 - val_accuracy: 0.8716\n",
      "Epoch 2/15\n",
      "606/606 - 20s - loss: 0.2737 - accuracy: 0.8886 - val_loss: 0.2691 - val_accuracy: 0.8888\n",
      "Epoch 3/15\n",
      "606/606 - 22s - loss: 0.2280 - accuracy: 0.9108 - val_loss: 0.2576 - val_accuracy: 0.8949\n",
      "Epoch 4/15\n",
      "606/606 - 22s - loss: 0.2026 - accuracy: 0.9220 - val_loss: 0.2586 - val_accuracy: 0.8999\n",
      "Epoch 5/15\n",
      "606/606 - 22s - loss: 0.1871 - accuracy: 0.9301 - val_loss: 0.2826 - val_accuracy: 0.8967\n",
      "Epoch 6/15\n",
      "606/606 - 22s - loss: 0.1793 - accuracy: 0.9325 - val_loss: 0.2571 - val_accuracy: 0.9078\n",
      "Epoch 7/15\n",
      "606/606 - 22s - loss: 0.1778 - accuracy: 0.9312 - val_loss: 0.2534 - val_accuracy: 0.9075\n",
      "Epoch 8/15\n",
      "606/606 - 22s - loss: 0.1640 - accuracy: 0.9378 - val_loss: 0.2671 - val_accuracy: 0.9071\n",
      "Epoch 9/15\n",
      "606/606 - 22s - loss: 0.1681 - accuracy: 0.9374 - val_loss: 0.2605 - val_accuracy: 0.9061\n",
      "Epoch 10/15\n",
      "606/606 - 22s - loss: 0.1877 - accuracy: 0.9289 - val_loss: 0.2975 - val_accuracy: 0.8930\n",
      "Epoch 11/15\n",
      "606/606 - 22s - loss: 0.2024 - accuracy: 0.9230 - val_loss: 0.2753 - val_accuracy: 0.8970\n",
      "Epoch 12/15\n",
      "606/606 - 22s - loss: 0.2023 - accuracy: 0.9220 - val_loss: 0.2733 - val_accuracy: 0.8924\n",
      "Epoch 13/15\n",
      "606/606 - 22s - loss: 0.2041 - accuracy: 0.9213 - val_loss: 0.2822 - val_accuracy: 0.8922\n",
      "Epoch 14/15\n",
      "606/606 - 23s - loss: 0.2240 - accuracy: 0.9124 - val_loss: 0.2909 - val_accuracy: 0.8884\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22a8645f048>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=create_model(vocab_size+1,embedding_dim,max_len)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=7)\n",
    "model.fit(training_padded,y_train,batch_size=64,epochs=15,verbose=2,validation_data=(testing_padded,y_test),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_text(sent):\n",
    "    sent=[sent]\n",
    "    seq=tokenizer.texts_to_sequences(sent)\n",
    "    padded=pad_sequences(seq,maxlen=max_len,padding=padding_type, truncating=trunc_type)\n",
    "    return model.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03785777]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_text('you broke my car,good job'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 32, 32)            96000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 129,141\n",
      "Trainable params: 129,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "606/606 - 1s - loss: 0.4100 - accuracy: 0.8152 - val_loss: 0.2762 - val_accuracy: 0.8862\n",
      "Epoch 2/15\n",
      "606/606 - 1s - loss: 0.2595 - accuracy: 0.8988 - val_loss: 0.2419 - val_accuracy: 0.9011\n",
      "Epoch 3/15\n",
      "606/606 - 1s - loss: 0.1834 - accuracy: 0.9295 - val_loss: 0.2361 - val_accuracy: 0.9179\n",
      "Epoch 4/15\n",
      "606/606 - 1s - loss: 0.1414 - accuracy: 0.9482 - val_loss: 0.2656 - val_accuracy: 0.9265\n",
      "Epoch 5/15\n",
      "606/606 - 1s - loss: 0.1093 - accuracy: 0.9595 - val_loss: 0.3202 - val_accuracy: 0.9247\n",
      "Epoch 6/15\n",
      "606/606 - 1s - loss: 0.0950 - accuracy: 0.9650 - val_loss: 0.2906 - val_accuracy: 0.9290\n",
      "Epoch 7/15\n",
      "606/606 - 1s - loss: 0.0844 - accuracy: 0.9683 - val_loss: 0.4429 - val_accuracy: 0.9287\n",
      "Epoch 8/15\n",
      "606/606 - 1s - loss: 0.0761 - accuracy: 0.9725 - val_loss: 0.4329 - val_accuracy: 0.9342\n",
      "Epoch 9/15\n",
      "606/606 - 1s - loss: 0.0704 - accuracy: 0.9720 - val_loss: 0.5098 - val_accuracy: 0.9360\n",
      "Epoch 10/15\n",
      "606/606 - 1s - loss: 0.0670 - accuracy: 0.9746 - val_loss: 0.5067 - val_accuracy: 0.9361\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22a92ac3f88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(units=32,activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Dense(units=10,activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Dense(units=1,activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model2.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model2.summary()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=7)\n",
    "model2.fit(training_padded,y_train,batch_size=64,epochs=15,verbose=2,validation_data=(testing_padded,y_test),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_text2(sent):\n",
    "    sent=[sent]\n",
    "    seq=tokenizer.texts_to_sequences(sent)\n",
    "    padded=pad_sequences(seq,maxlen=max_len,padding=padding_type, truncating=trunc_type)\n",
    "    return model2.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999976]]\n"
     ]
    }
   ],
   "source": [
    "sent=\"you broke my car , good job\"\n",
    "print(prediction_text2(sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
